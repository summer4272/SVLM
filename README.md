# Small Vision Language Model (SVLM)

## ğŸ— æ¨¡å‹ç»“æ„ç¤ºæ„ (Model Architecture)
![æ¨¡å‹ç»“æ„](Image/MODEL.png)

---
## åº–ä¸è§£ç‰› (Starting small, thinking big)

æœ¬é¡¹ç›®ä»é›¶å¼€å§‹æ‰‹æ“è§†è§‰-æ–‡æœ¬ç»Ÿä¸€çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œ**æ˜¾å­˜ 8GB å³å¯è®­ç»ƒ**ï¼Œé€‚åˆåˆå­¦è€…å’Œä½ç®—åŠ›äººç¾¤è¿›è¡Œå®è·µä¸å­¦ä¹ ã€‚  
This project builds a **vision-language unified multimodal model from scratch**, requiring **only 8GB GPU memory** to train. It is designed for beginners and users with limited resources.  

ğŸ“Œ **ç‰¹ç‚¹ / Features:**  
- ğŸ”§ ä»é›¶å®ç° / Implemented from scratch  
- ğŸ’» ä½ç®—åŠ›å¯è·‘ / Runs on limited resources  
- ğŸ“š é€‚åˆå­¦ä¹ ä¸å®è·µ / Suitable for learning & practice  
- ğŸŒ ç®€æ´é«˜æ•ˆ / Compact & efficient  

---
## ğŸ“· æ•ˆæœå±•ç¤º (Project Showcase)

![ç»“æœæ¼”ç¤º](Image/videotogif.gif)


---
## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quickstart)

## ğŸ”§ ç¬¬ 1 æ­¥ï¼šæ¨¡å‹é…ç½® (Step 1: Model Setup)

```bash
# å…‹éš†æœ¬é¡¹ç›®ä»£ç ä»“åº“
# Clone the project repository
git clone https://github.com/summer4272/SVLM.git
cd SVLM
```
```
# ä¸‹è½½ DINOv2-base æ¨¡å‹ (è§†è§‰ç¼–ç å™¨)
# Download the DINOv2-base model (vision encoder)
git clone https://huggingface.co/facebook/dinov2-base

```
```
# ä¸‹è½½ AutoProcessorï¼ˆä»…éœ€ tokenizer é…ç½®ï¼Œå¯ä¸ä¸‹è½½å®Œæ•´æ¨¡å‹ï¼‰
# Download AutoProcessor (only tokenizer is needed; model weights can be omitted)
git clone https://huggingface.co/llava-hf/llava-1.5-7b-hf

```
## âš™ï¸ ç¬¬ 2 æ­¥ï¼šç¯å¢ƒé…ç½® (Step 2: Environment Setup)

é¡¹ç›®æä¾›äº† `environment.yml` æ–‡ä»¶ï¼Œå¯ç›´æ¥åŸºäºè¯¥æ–‡ä»¶åˆ›å»º Conda ç¯å¢ƒã€‚  
The project provides an `environment.yml` file, which allows you to create the Conda environment directly.

```bash
# ä½¿ç”¨ environment.yml åˆ›å»ºåä¸º SVLM çš„ç¯å¢ƒ
# Create a new Conda environment named "SVLM" from environment.yml
conda env create -f environment.yml -n SVLM
```
## ğŸ“‚ ç¬¬ 3 æ­¥ï¼šä¸‹è½½è®­ç»ƒæ•°æ®é›† (Step 3: Download Training Dataset)

é¡¹ç›®ä½¿ç”¨ **Chinese-LLaVA-Vision-Instructions** æ•°æ®é›†ã€‚  
You can download the **Chinese-LLaVA-Vision-Instructions** dataset as follows:

```bash
# å…‹éš†æ•°æ®é›† 
# Clone the dataset 
git clone https://huggingface.co/datasets/Summer1231/SVLM-Data
```
## ğŸ¯ è®­ç»ƒæŒ‡ä»¤ (Training Commands)

æœ¬é¡¹ç›®é‡‡ç”¨ **åŒé˜¶æ®µè®­ç»ƒ**ï¼š  
This project uses a **two-stage training** strategy.

---

### ğŸ”µ é˜¶æ®µä¸€ï¼šè®­ç»ƒè§†è§‰å¡” (Stage 1: Vision-Heavy Training)

```bash
python train.py train \
  --stage stage1 \
  --model_dir "llava-1.5-7b-hf" \
  --dinov2_path "dinov2-base" \
  --data_dir "Svlmdata" \
  --jsonl_name "pretrain_vlm_data.jsonl" \
  --image_dir "pretrain_images" \
  --unfreeze_lm_top_layers 2 \
  --train_text_embed true \
  --train_dino_proj true \
  --batch_size 2 \
  --epochs 5 \
  --steps_per_epoch 1500 \
  --wandb_project "vlm-train" \
  --run_name "s1-vision-heavy"
```

### ğŸŸ¢ é˜¶æ®µäºŒï¼šè®­ç»ƒè¯­è¨€ä¾§ (Stage 2: Text-Heavy Training)
```bash
python train.py train \
  --stage stage2 \
  --model_dir "llava-1.5-7b-hf" \
  --dinov2_path "dinov2-base" \
  --data_dir "Svlmdata" \
  --jsonl_name "sft_vlm_data.jsonl" \
  --image_dir "sft_images" \
  --unfreeze_lm_top_layers 14 \
  --train_text_embed true \
  --train_dino_proj false \
  --batch_size 4 \
  --epochs 10 \
  --steps_per_epoch -1 \
  --ckpt "s1-vision-heavy/epoch.pt" \
  --wandb_project "vlm-train" \
  --run_name "s2-text-heavy"
```
### ğŸ§ª éªŒè¯æ¨¡å‹ (Validation)
```bash
python train.py validate \
  --ckpt "s2-text-heavy/epoch.pt" \
  --model_dir "llava-1.5-7b-hf" \
  --dinov2_path "dinov2-base" \
  --data_dir "Svlmdata" \
  --jsonl_name "sft_vlm_data.jsonl" \
  --image_dir "sft_images" \
  --steps_per_epoch -1 \
  --amp_dtype bfloat16

```
### ğŸ’¡ æ¨ç† (Inference)
```bash
python train.py infer \
  --ckpt "epoch.pt" \
  --model_dir "llava-1.5-7b-hf" \
  --dinov2_path "dinov2-base" \
  --image "your_image.jpg" \
  --prompt "è¯·æ ¹æ®å›¾åƒå›ç­”ï¼šè¿™å¼ å›¾é‡Œæœ‰ä»€ä¹ˆï¼Ÿ" \
  --d_in 4096 \
  --d_model 1024 \
  --n_heads 4 \
  --n_layers 14
```
---

## ğŸ“ˆ è®­ç»ƒæ•ˆæœæ›²çº¿ (Training Curves)
```
è¿™é‡Œä»…ä»…å±•ç¤ºäº†ç¬¬ä¸€é˜¶æ®µè®­ç»ƒæ›²çº¿
```
![è®­ç»ƒæ›²çº¿](Image/train.png)
