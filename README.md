# Small Vision Language Model (SVLM)

## ğŸ— æ¨¡å‹ç»“æ„ç¤ºæ„ (Model Architecture)
![æ¨¡å‹ç»“æ„](Image/MODEL.png)

---
## åº–ä¸è§£ç‰› (Starting small, thinking big)

æœ¬é¡¹ç›®ä»é›¶å¼€å§‹æ‰‹æ“è§†è§‰-æ–‡æœ¬ç»Ÿä¸€çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œ**æ˜¾å­˜ 8GB å³å¯è®­ç»ƒ**ï¼Œé€‚åˆåˆå­¦è€…å’Œä½ç®—åŠ›äººç¾¤è¿›è¡Œå®è·µä¸å­¦ä¹ ã€‚  
This project builds a **vision-language unified multimodal model from scratch**, requiring **only 8GB GPU memory** to train. It is designed for beginners and users with limited resources.  

ğŸ“Œ **ç‰¹ç‚¹ / Features:**  
- ğŸ”§ ä»é›¶å®ç° / Implemented from scratch  
- ğŸ’» ä½ç®—åŠ›å¯è·‘ / Runs on limited resources  
- ğŸ“š é€‚åˆå­¦ä¹ ä¸å®è·µ / Suitable for learning & practice  
- ğŸŒ ç®€æ´é«˜æ•ˆ / Compact & efficient  

---
## ğŸ“· æ•ˆæœå±•ç¤º (Project Showcase)

![ç»“æœæ¼”ç¤º](Image/videotogif.gif)


---
## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quickstart)

## ğŸ”§ ç¬¬ 1 æ­¥ï¼šæ¨¡å‹é…ç½® (Step 1: Model Setup)

```bash
# å…‹éš†æœ¬é¡¹ç›®ä»£ç ä»“åº“
# Clone the project repository
git clone https://github.com/summer4272/SVLM.git
cd SVLM
```
```
# ä¸‹è½½ DINOv2-base æ¨¡å‹ (è§†è§‰ç¼–ç å™¨)
# Download the DINOv2-base model (vision encoder)
git clone https://huggingface.co/facebook/dinov2-base

```
```
# ä¸‹è½½ AutoProcessorï¼ˆä»…éœ€ tokenizer é…ç½®ï¼Œå¯ä¸ä¸‹è½½å®Œæ•´æ¨¡å‹ï¼‰
# Download AutoProcessor (only tokenizer is needed; model weights can be omitted)
git clone https://huggingface.co/llava-hf/llava-1.5-7b-hf

```
## âš™ï¸ ç¬¬ 2 æ­¥ï¼šç¯å¢ƒé…ç½® (Step 2: Environment Setup)

é¡¹ç›®æä¾›äº† `environment.yml` æ–‡ä»¶ï¼Œå¯ç›´æ¥åŸºäºè¯¥æ–‡ä»¶åˆ›å»º Conda ç¯å¢ƒã€‚  
The project provides an `environment.yml` file, which allows you to create the Conda environment directly.

```bash
# ä½¿ç”¨ environment.yml åˆ›å»ºåä¸º SVLM çš„ç¯å¢ƒ
# Create a new Conda environment named "SVLM" from environment.yml
conda env create -f environment.yml -n SVLM
```
## ğŸ“‚ ç¬¬ 3 æ­¥ï¼šä¸‹è½½è®­ç»ƒæ•°æ®é›† (Step 3: Download Training Dataset)

é¡¹ç›®ä½¿ç”¨ **Chinese-LLaVA-Vision-Instructions** æ•°æ®é›†ã€‚  
You can download the **Chinese-LLaVA-Vision-Instructions** dataset as follows:

```bash
# å…‹éš†æ•°æ®é›† (ä½¿ç”¨é•œåƒç«™ç‚¹ä¸‹è½½)
# Clone the dataset (using hf-mirror for faster access)
git clone https://hf-mirror.com/datasets/LinkSoul/Chinese-LLaVA-Vision-Instructions
```

---

## ğŸ“ˆ è®­ç»ƒæ•ˆæœæ›²çº¿ (Training Curves)

![è®­ç»ƒæ›²çº¿](Image/train.png)
